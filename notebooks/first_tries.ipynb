{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4437cb32-df61-4b36-9cb1-17ffe9f9cb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import pyttsx3\n",
    "import time\n",
    "import queue\n",
    "import threading\n",
    "from ultralytics import YOLO\n",
    "\n",
    "\n",
    "# Carregar modelo leve (voc√™ pode trocar por outro)\n",
    "model = YOLO('yolov8s.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c30fe6a-b73f-4c31-8675-5fbdc01fe9b7",
   "metadata": {},
   "source": [
    "# Primeira tentativa rodando o Yolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9571169-820a-4027-8318-3d35543dbfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Carrega o modelo\n",
    "model = YOLO('yolov8s.pt')\n",
    "\n",
    "# Define classes relevantes √† navega√ß√£o\n",
    "CLASSES_UTEIS = ['person', 'bench', 'bicycle', 'car', 'chair', 'stop sign']\n",
    "\n",
    "# Abre o v√≠deo (Etapa 1)\n",
    "video_path = 'video_certo_edat.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Detec√ß√£o\n",
    "    results = model(frame, verbose=False)\n",
    "    frame_copy = frame.copy()\n",
    "\n",
    "    for result in results:\n",
    "        for box in result.boxes:\n",
    "            cls = model.names[int(box.cls)]\n",
    "            conf = float(box.conf)\n",
    "\n",
    "            # S√≥ desenha se estiver na lista de interesse\n",
    "            if cls in CLASSES_UTEIS and conf > 0.5:\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                label = f\"{cls} ({conf:.2f})\"\n",
    "                cv2.rectangle(frame_copy, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                cv2.putText(frame_copy, label, (x1, y1 - 10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"Detec√ß√£o de Objetos Relevantes\", frame_copy)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50407091-929d-46b6-9947-c29bcd280a82",
   "metadata": {},
   "source": [
    "# Com o ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bcb4426-2bbb-43f2-88be-85d58899fa32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolov8s.pt')\n",
    "\n",
    "# Classes √∫teis\n",
    "CLASSES_UTEIS = ['person', 'bench', 'bicycle', 'car', 'chair', 'stop sign']\n",
    "\n",
    "video_path = r\"C:/codes/unicamp/MC949/T3/videos/VID_20251014_120019333.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    height, width, _ = frame.shape\n",
    "\n",
    "# Define ROI: regi√£o central (50% da largura e altura)\n",
    "    x1_roi = int(width * 0.10)\n",
    "    x2_roi = int(width * 0.70)\n",
    "    y1_roi = int(height * 0.35)\n",
    "    y2_roi = int(height * 0.75)\n",
    "\n",
    "\n",
    "    # Desenha ROI (s√≥ pra visualizar)\n",
    "    cv2.rectangle(frame, (x1_roi, y1_roi), (x2_roi, y2_roi), (255, 255, 0), 2)\n",
    "\n",
    "    results = model(frame, verbose=False)\n",
    "\n",
    "    for result in results:\n",
    "        for box in result.boxes:\n",
    "            cls = model.names[int(box.cls)]\n",
    "            conf = float(box.conf)\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "\n",
    "            # Centro da caixa detectada\n",
    "            cx = int((x1 + x2) / 2)\n",
    "            cy = int((y1 + y2) / 2)\n",
    "\n",
    "            # S√≥ mostra objetos dentro da ROI\n",
    "            if (cls in CLASSES_UTEIS) and (x1_roi < cx < x2_roi) and (y1_roi < cy < y2_roi) and conf > 0.5:\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                cv2.putText(frame, f\"{cls} ({conf:.2f})\", (x1, y1 - 10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"Detec√ß√£o com ROI - Zona de Interesse Frontal\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce77d663-6222-4ba1-8d31-808ecf730739",
   "metadata": {},
   "source": [
    "## Etapa 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9d35107-2e0f-4442-8737-fe912c2dfaa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\gabrielgomes/.cache\\torch\\hub\\intel-isl_MiDaS_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights:  None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\gabrielgomes/.cache\\torch\\hub\\rwightman_gen-efficientnet-pytorch_master\n",
      "Using cache found in C:\\Users\\gabrielgomes/.cache\\torch\\hub\\intel-isl_MiDaS_master\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 143\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prev_gray \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    141\u001b[0m     prev_gray \u001b[38;5;241m=\u001b[39m gray\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m--> 143\u001b[0m flow \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalcOpticalFlowFarneback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprev_gray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m                                    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpyr_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mwinsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m21\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mpoly_n\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoly_sigma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;66;03m# YOLO detec√ß√£o\u001b[39;00m\n\u001b[0;32m    149\u001b[0m results \u001b[38;5;241m=\u001b[39m yolo(frame, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "############################################\n",
    "# 1) MODELOS: YOLO (detec√ß√£o) + MiDaS (profundidade)\n",
    "############################################\n",
    "\n",
    "# YOLO ‚Äì use o mesmo que voc√™ j√° calibrou\n",
    "yolo = YOLO('yolov8s.pt')\n",
    "\n",
    "# MiDaS pequeno (mais leve pra CPU) ‚Äì via torch.hub\n",
    "device = torch.device('cpu')\n",
    "midas = torch.hub.load('intel-isl/MiDaS', 'MiDaS_small', trust_repo=True).to(device).eval()\n",
    "transform = torch.hub.load('intel-isl/MiDaS', 'transforms', trust_repo=True).small_transform\n",
    "\n",
    "############################################\n",
    "# 2) CONFIGS DO PROJETO\n",
    "############################################\n",
    "\n",
    "# Suas classes alvo (mapeadas para COCO)\n",
    "CLASSES_UTEIS = [\n",
    "    'person', 'bicycle', 'car', 'bench',\n",
    "    'chair', 'stop sign', 'potted plant'  # aproxima lixeira em alguns contextos\n",
    "]\n",
    "\n",
    "# ROI ‚Äì sua vers√£o levemente √† esquerda e central-baixa\n",
    "def get_roi(frame):\n",
    "    h, w = frame.shape[:2]\n",
    "    x1 = int(w * 0.10)\n",
    "    x2 = int(w * 0.70)\n",
    "    y1 = int(h * 0.35)\n",
    "    y2 = int(h * 0.75)\n",
    "    return (x1, y1, x2, y2)\n",
    "\n",
    "# Calibra√ß√£o (escala) da profundidade:\n",
    "# MiDaS produz \"inverso de profundidade\" arbitr√°rio. \n",
    "# Para converter para \"metros aproximados\", defina um ponto de refer√™ncia no seu v√≠deo:\n",
    "#   ‚Äì me√ßa uma dist√¢ncia real (ex.: um poste a ~5m) e ajuste abaixo at√© bater.\n",
    "# Use um valor inicial (heur√≠stico) e ajuste no relat√≥rio.\n",
    "METER_SCALE = 4.0   # fator de escala (ajuste emp√≠rico no seu v√≠deo)\n",
    "\n",
    "# Thresholds para risco (ajuste fino no seu v√≠deo)\n",
    "DIST_DANGER_M = 2.5    # abaixo disso, j√° √© ‚Äúperto‚Äù\n",
    "FLOW_APPROACH_MIN = 0.6 # velocidade relativa m√©dia (px/frame) para considerar aproxima√ß√£o\n",
    "CENTER_BONUS = 0.15     # b√¥nus de risco se bbox estiver no centro da ROI\n",
    "\n",
    "############################################\n",
    "# 3) Fun√ß√µes utilit√°rias\n",
    "############################################\n",
    "\n",
    "def predict_depth(frame_bgr):\n",
    "    \"\"\"Gera mapa de profundidade (inverso) com MiDaS + filtros (median + bilateral).\"\"\"\n",
    "    img_rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)\n",
    "    inp = transform(img_rgb).to(device)\n",
    "    with torch.no_grad():\n",
    "        pred = midas(inp)\n",
    "        pred = torch.nn.functional.interpolate(\n",
    "            pred.unsqueeze(1),\n",
    "            size=img_rgb.shape[:2],\n",
    "            mode='bicubic',\n",
    "            align_corners=False\n",
    "        ).squeeze().cpu().numpy()\n",
    "    # normaliza para [0,1] (inverso de profundidade)\n",
    "    pred_norm = (pred - pred.min()) / (pred.max() - pred.min() + 1e-6)\n",
    "    # p√≥s-processamento: suaviza√ß√£o\n",
    "    pred_norm = cv2.medianBlur((pred_norm*255).astype(np.uint8), 5)\n",
    "    pred_norm = cv2.bilateralFilter(pred_norm, d=7, sigmaColor=50, sigmaSpace=7)\n",
    "    pred_norm = pred_norm.astype(np.float32) / 255.0\n",
    "    return pred_norm  # 0..1 (maior = mais perto)\n",
    "\n",
    "def invdepth_to_meters(invdepth):\n",
    "    \"\"\"Converte inverso de profundidade normalizado para dist√¢ncia aproximada em metros.\"\"\"\n",
    "    inv = float(invdepth)\n",
    "    inv = max(inv, 1e-3)  # evita divis√£o por zero\n",
    "    # dist√¢ncia ~ (constante / invdepth)\n",
    "    meters = METER_SCALE / inv\n",
    "    return meters\n",
    "\n",
    "def bbox_center(b):\n",
    "    x1, y1, x2, y2 = b\n",
    "    return (int((x1+x2)//2), int((y1+y2)//2))\n",
    "\n",
    "def iou(a, b):\n",
    "    ax1, ay1, ax2, ay2 = a; bx1, by1, bx2, by2 = b\n",
    "    inter_x1, inter_y1 = max(ax1, bx1), max(ay1, by1)\n",
    "    inter_x2, inter_y2 = min(ax2, bx2), min(ay2, by2)\n",
    "    iw, ih = max(0, inter_x2 - inter_x1), max(0, inter_y2 - inter_y1)\n",
    "    inter = iw * ih\n",
    "    area_a = (ax2-ax1)*(ay2-ay1); area_b = (bx2-bx1)*(by2-by1)\n",
    "    union = area_a + area_b - inter + 1e-6\n",
    "    return inter/union\n",
    "\n",
    "def mean_flow_in_bbox(flow, bbox):\n",
    "    x1, y1, x2, y2 = bbox\n",
    "    x1, y1 = max(0, x1), max(0, y1)\n",
    "    fx = flow[y1:y2, x1:x2, 0]\n",
    "    fy = flow[y1:y2, x1:x2, 1]\n",
    "    if fx.size == 0: \n",
    "        return 0.0, 0.0, 0.0\n",
    "    mag = np.sqrt(fx*fx + fy*fy)\n",
    "    return float(np.mean(fx)), float(np.mean(fy)), float(np.mean(mag))\n",
    "\n",
    "def center_weight_in_roi(cx, cy, roi):\n",
    "    x1, y1, x2, y2 = roi\n",
    "    rx, ry = (x1+x2)/2, (y1+y2)/2\n",
    "    rw, rh = (x2-x1), (y2-y1)\n",
    "    dx = abs(cx - rx)/ (rw/2 + 1e-6)\n",
    "    dy = abs(cy - ry)/ (rh/2 + 1e-6)\n",
    "    d = np.sqrt(dx*dx + dy*dy)  # 0 = centro, 1 = borda\n",
    "    return max(0.0, 1.0 - min(1.0, d))  # peso 0..1 (1 = centro)\n",
    "\n",
    "############################################\n",
    "# 4) Loop do v√≠deo com ROI + profundidade + fluxo + risco\n",
    "############################################\n",
    "\n",
    "video_path = r\"C:/codes/unicamp/MC949/T3/videos/VID_20251014_120019333.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "prev_gray = None\n",
    "prev_boxes = []\n",
    "\n",
    "while True:\n",
    "    ok, frame = cap.read()\n",
    "    if not ok:\n",
    "        break\n",
    "\n",
    "    h, w = frame.shape[:2]\n",
    "    roi = get_roi(frame)\n",
    "\n",
    "    # Desenha ROI\n",
    "    cv2.rectangle(frame, (roi[0], roi[1]), (roi[2], roi[3]), (255, 255, 0), 2)\n",
    "\n",
    "    # Profundidade do frame atual\n",
    "    invdepth = predict_depth(frame)  # 0..1, maior = mais perto\n",
    "\n",
    "    # Fluxo √≥ptico (com o frame anterior)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    if prev_gray is None:\n",
    "        prev_gray = gray.copy()\n",
    "\n",
    "    flow = cv2.calcOpticalFlowFarneback(prev_gray, gray,\n",
    "                                        None, pyr_scale=0.5, levels=3,\n",
    "                                        winsize=21, iterations=3,\n",
    "                                        poly_n=5, poly_sigma=1.2, flags=0)\n",
    "\n",
    "    # YOLO detec√ß√£o\n",
    "    results = yolo(frame, verbose=False)\n",
    "\n",
    "    # Seleciona objetos de interesse **dentro da ROI**\n",
    "    candidates = []\n",
    "    for r in results:\n",
    "        for b in r.boxes:\n",
    "            cls = yolo.names[int(b.cls)]\n",
    "            conf = float(b.conf)\n",
    "            if conf < 0.45 or cls not in CLASSES_UTEIS:\n",
    "                continue\n",
    "            x1, y1, x2, y2 = map(int, b.xyxy[0])\n",
    "            cx, cy = bbox_center((x1, y1, x2, y2))\n",
    "            if not (roi[0] < cx < roi[2] and roi[1] < cy < roi[3]):\n",
    "                continue\n",
    "\n",
    "            # Profundidade dentro do bbox (mediana √© robusta)\n",
    "            x1c, y1c = max(0, x1), max(0, y1)\n",
    "            x2c, y2c = min(w, x2), min(h, y2)\n",
    "            box_depth = invdepth[y1c:y2c, x1c:x2c]\n",
    "            if box_depth.size == 0:\n",
    "                continue\n",
    "            inv_med = float(np.median(box_depth))\n",
    "            dist_m = invdepth_to_meters(inv_med)\n",
    "\n",
    "            # Fluxo m√©dio (velocidade relativa)\n",
    "            mx, my, mmag = mean_flow_in_bbox(flow, (x1c, y1c, x2c, y2c))\n",
    "            # Heur√≠stica de aproxima√ß√£o: m√≥dulo + componente vertical em dire√ß√£o √† c√¢mera:\n",
    "            approach = mmag + max(0.0, -my)  # se my negativo (vindo \"pra baixo\"), soma\n",
    "\n",
    "            # Centralidade na ROI (0..1)\n",
    "            cweight = center_weight_in_roi(cx, cy, roi)\n",
    "\n",
    "            candidates.append({\n",
    "                'bbox': (x1, y1, x2, y2),\n",
    "                'cls': cls, 'conf': conf,\n",
    "                'dist_m': dist_m,\n",
    "                'flow_mag': mmag,\n",
    "                'approach': approach,\n",
    "                'center_w': cweight,\n",
    "                'center': (cx, cy)\n",
    "            })\n",
    "\n",
    "    # Heur√≠stica de PRIORIDADE: menor dist√¢ncia + mais central + maior aproxima√ß√£o\n",
    "    target = None\n",
    "    if candidates:\n",
    "        # score simples: pondera dist√¢ncia (inverso), centralidade e aproxima√ß√£o\n",
    "        for c in candidates:\n",
    "            inv_d = 1.0 / (c['dist_m'] + 1e-6)\n",
    "            c['score'] = 1.5*inv_d + 1.0*c['center_w'] + 0.8*c['approach']\n",
    "        target = max(candidates, key=lambda x: x['score'])\n",
    "\n",
    "    # Desenha todos os candidatos e destaca o \"narrado\"\n",
    "    for c in candidates:\n",
    "        x1, y1, x2, y2 = c['bbox']\n",
    "        color = (0, 255, 0)\n",
    "        if target is not None and c is target:\n",
    "            color = (0, 0, 255)  # vermelho = alvo narrado\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "        txt = f\"{c['cls']} {c['dist_m']:.1f}m  v~{c['flow_mag']:.2f}\"\n",
    "        cv2.putText(frame, txt, (x1, max(20, y1-8)), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "\n",
    "    # Regra de RISCO (alerta)\n",
    "    alert_text = \"\"\n",
    "    if target:\n",
    "        near = target['dist_m'] <= DIST_DANGER_M\n",
    "        fast = target['approach'] >= FLOW_APPROACH_MIN\n",
    "        centered = target['center_w'] >= (1.0 - CENTER_BONUS)  # mais central\n",
    "\n",
    "        if (near and fast) or (near and centered):\n",
    "            alert_text = f\"ALERTA: {target['cls']} a {target['dist_m']:.1f} m\"\n",
    "            cv2.putText(frame, alert_text, (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,0,255), 3)\n",
    "\n",
    "    # Mostra\n",
    "    cv2.imshow(\"Etapa 3 - Profundidade, Velocidade e Risco\", frame)\n",
    "    prev_gray = gray.copy()\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9644b10-89c2-4691-ae05-d03f5c60dad5",
   "metadata": {},
   "source": [
    "# Pr√≥xima Etapa - Narra√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee797798-eeed-43b6-9cff-0049e5bd6862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gabrielgomes\\AppData\\Local\\Programs\\Python\\Python311\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94342c29-508a-4eab-9d78-c005bd885dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\gabrielgomes/.cache\\torch\\hub\\intel-isl_MiDaS_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights:  None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\gabrielgomes/.cache\\torch\\hub\\rwightman_gen-efficientnet-pytorch_master\n",
      "Using cache found in C:\\Users\\gabrielgomes/.cache\\torch\\hub\\intel-isl_MiDaS_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîä Aten√ß√£o: car a 0.0 metros √† frente.\n",
      "üîä Aten√ß√£o: car a 0.0 metros √† frente.\n",
      "üîä Aten√ß√£o: car a 0.0 metros √† frente.\n",
      "üîä Aten√ß√£o: car a 0.0 metros √† frente.\n",
      "üîä Aten√ß√£o: car a 0.0 metros √† frente.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 74\u001b[0m\n\u001b[0;32m     69\u001b[0m cv2\u001b[38;5;241m.\u001b[39mrectangle(frame, (x1_roi, y1_roi), (x2_roi, y2_roi), (\u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m########################################\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# DETEC√á√ÉO\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m########################################\u001b[39;00m\n\u001b[1;32m---> 74\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m# Depth map\u001b[39;00m\n\u001b[0;32m     77\u001b[0m input_batch \u001b[38;5;241m=\u001b[39m transform(frame)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\ultralytics\\engine\\model.py:187\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, source, stream, **kwargs)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    160\u001b[0m     source: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m Path \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m Image\u001b[38;5;241m.\u001b[39mImage \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mtuple\u001b[39m \u001b[38;5;241m|\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray \u001b[38;5;241m|\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    161\u001b[0m     stream: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    163\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[0;32m    164\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;124;03m    Alias for the predict method, enabling the model instance to be callable for predictions.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;124;03m        ...     print(f\"Detected {len(r)} objects in image\")\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 187\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\ultralytics\\engine\\model.py:557\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[0;32m    555\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_prompts\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n\u001b[0;32m    556\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mset_prompts(prompts)\n\u001b[1;32m--> 557\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mpredict_cli(source\u001b[38;5;241m=\u001b[39msource) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\ultralytics\\engine\\predictor.py:229\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[1;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 229\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n",
      "File \u001b[1;32mc:\\Users\\gabrielgomes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\_contextlib.py:38\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m---> 38\u001b[0m         response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     41\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     42\u001b[0m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\ultralytics\\engine\\predictor.py:336\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[1;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m--> 336\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    337\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39membed:\n\u001b[0;32m    338\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m [preds] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(preds, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m preds  \u001b[38;5;66;03m# yield embedding tensors\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\ultralytics\\engine\\predictor.py:184\u001b[0m, in \u001b[0;36mBasePredictor.inference\u001b[1;34m(self, im, *args, **kwargs)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run inference on a given image using the specified model and arguments.\"\"\"\u001b[39;00m\n\u001b[0;32m    179\u001b[0m visualize \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    180\u001b[0m     increment_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_dir \u001b[38;5;241m/\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mstem, mkdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mvisualize \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_type\u001b[38;5;241m.\u001b[39mtensor)\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    183\u001b[0m )\n\u001b[1;32m--> 184\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gabrielgomes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gabrielgomes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\ultralytics\\nn\\autobackend.py:640\u001b[0m, in \u001b[0;36mAutoBackend.forward\u001b[1;34m(self, im, augment, visualize, embed, **kwargs)\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;66;03m# PyTorch\u001b[39;00m\n\u001b[0;32m    639\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpt \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn_module:\n\u001b[1;32m--> 640\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    642\u001b[0m \u001b[38;5;66;03m# TorchScript\u001b[39;00m\n\u001b[0;32m    643\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjit:\n",
      "File \u001b[1;32mc:\\Users\\gabrielgomes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gabrielgomes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\ultralytics\\nn\\tasks.py:139\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[1;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\ultralytics\\nn\\tasks.py:157\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[1;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_augment(x)\n\u001b[1;32m--> 157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\ultralytics\\nn\\tasks.py:180\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[1;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[1;32m--> 180\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[0;32m    181\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(x \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "File \u001b[1;32mc:\\Users\\gabrielgomes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gabrielgomes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\ultralytics\\nn\\modules\\conv.py:93\u001b[0m, in \u001b[0;36mConv.forward_fuse\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_fuse\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     84\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;124;03m    Apply convolution and activation without batch normalization.\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;124;03m        (torch.Tensor): Output tensor.\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\gabrielgomes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gabrielgomes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\gabrielgomes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    547\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 548\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gabrielgomes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:543\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[0;32m    533\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[0;32m    534\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    541\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[0;32m    542\u001b[0m     )\n\u001b[1;32m--> 543\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    544\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[0;32m    545\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "############################################\n",
    "# 1) CONFIGURA√á√ÉO DOS MODELOS\n",
    "############################################\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = YOLO('yolov8s.pt')\n",
    "\n",
    "# Carrega modelo de profundidade MiDaS\n",
    "midas = torch.hub.load('intel-isl/MiDaS', 'MiDaS_small', trust_repo=True).to(device).eval()\n",
    "transform = torch.hub.load('intel-isl/MiDaS', 'transforms', trust_repo=True).small_transform\n",
    "\n",
    "############################################\n",
    "# 2) CONFIGURA√á√ÉO DE CLASSES E ROI\n",
    "############################################\n",
    "CLASSES_UTEIS = ['person', 'bench', 'bicycle', 'car', 'chair', 'stop sign']\n",
    "METER_SCALE = 4.0  # fator aproximado pra converter profundidade\n",
    "\n",
    "# ROI ‚Äî ajust√°vel\n",
    "ROI_X1, ROI_X2 = 0.15, 0.75\n",
    "ROI_Y1, ROI_Y2 = 0.35, 0.75\n",
    "\n",
    "############################################\n",
    "# 3) CONFIGURA√á√ÉO DO TTS\n",
    "############################################\n",
    "tts = pyttsx3.init()\n",
    "tts.setProperty('rate', 170)  # velocidade da fala\n",
    "tts.setProperty('voice', 'brazil')  # tenta selecionar voz em portugu√™s (pode variar por SO)\n",
    "\n",
    "# Controle de narra√ß√£o\n",
    "ultima_fala = 0\n",
    "INTERVALO_FALA = 4  # segundos entre mensagens\n",
    "\n",
    "############################################\n",
    "# 4) FUN√á√ÉO DE NARRA√á√ÉO\n",
    "############################################\n",
    "def narrar(mensagem):\n",
    "    global ultima_fala\n",
    "    agora = time.time()\n",
    "    if agora - ultima_fala > INTERVALO_FALA:\n",
    "        print(\"üîä\", mensagem)\n",
    "        tts.say(mensagem)\n",
    "        tts.runAndWait()\n",
    "        ultima_fala = agora\n",
    "\n",
    "############################################\n",
    "# 5) LOOP PRINCIPAL\n",
    "############################################\n",
    "video_path = r\"C:/codes/unicamp/MC949/T3/videos/VID_20251014_120019333.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    height, width, _ = frame.shape\n",
    "\n",
    "    # Define ROI\n",
    "    x1_roi = int(width * ROI_X1)\n",
    "    x2_roi = int(width * ROI_X2)\n",
    "    y1_roi = int(height * ROI_Y1)\n",
    "    y2_roi = int(height * ROI_Y2)\n",
    "    cv2.rectangle(frame, (x1_roi, y1_roi), (x2_roi, y2_roi), (255, 255, 0), 2)\n",
    "\n",
    "    ########################################\n",
    "    # DETEC√á√ÉO\n",
    "    ########################################\n",
    "    results = model(frame, verbose=False)\n",
    "\n",
    "    # Depth map\n",
    "    input_batch = transform(frame).to(device)\n",
    "    with torch.no_grad():\n",
    "        depth = midas(input_batch)\n",
    "        depth = torch.nn.functional.interpolate(depth.unsqueeze(1),\n",
    "                                                size=frame.shape[:2],\n",
    "                                                mode='bilinear',\n",
    "                                                align_corners=False).squeeze().cpu().numpy()\n",
    "\n",
    "    alerta_critico = False\n",
    "    for result in results:\n",
    "        for box in result.boxes:\n",
    "            cls = model.names[int(box.cls)]\n",
    "            conf = float(box.conf)\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "\n",
    "            if cls not in CLASSES_UTEIS or conf < 0.5:\n",
    "                continue\n",
    "\n",
    "            # Centro da detec√ß√£o\n",
    "            cx, cy = (x1 + x2) // 2, (y1 + y2) // 2\n",
    "\n",
    "            # S√≥ considera dentro da ROI\n",
    "            if not (x1_roi < cx < x2_roi and y1_roi < cy < y2_roi):\n",
    "                continue\n",
    "\n",
    "            # Estima dist√¢ncia\n",
    "            obj_depth = np.median(depth[y1:y2, x1:x2])\n",
    "            distancia_m = METER_SCALE / max(obj_depth, 0.1)\n",
    "\n",
    "            # Exibe info na tela\n",
    "            texto = f\"{cls} {distancia_m:.1f}m\"\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, texto, (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "\n",
    "            ########################################\n",
    "            # L√ìGICA DE ALERTA E NARRA√á√ÉO\n",
    "            ########################################\n",
    "            if distancia_m < 2.0:  # obst√°culo muito pr√≥ximo\n",
    "                alerta_critico = True\n",
    "                narrar(f\"Aten√ß√£o: {cls} a {distancia_m:.1f} metros √† frente.\")\n",
    "            elif distancia_m < 4.0:\n",
    "                narrar(f\"{cls} a {distancia_m:.1f} metros. Siga em frente.\")\n",
    "\n",
    "    # Mostra telemetria opcional\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    cv2.putText(frame, f\"FPS: {fps:.1f}\", (20, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"Percep√ß√£o + Narra√ß√£o\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2b21890-8a91-45f0-9969-d9317ec65d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\gabrielgomes/.cache\\torch\\hub\\intel-isl_MiDaS_master\n",
      "c:\\Users\\gabrielgomes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\timm\\models\\layers\\__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights:  None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\gabrielgomes/.cache\\torch\\hub\\rwightman_gen-efficientnet-pytorch_master\n",
      "Using cache found in C:\\Users\\gabrielgomes/.cache\\torch\\hub\\intel-isl_MiDaS_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voz selecionada: Microsoft Maria Desktop - Portuguese(Brazil)\n",
      "üîä Aten√ß√£o: car a 0.0 metros √† frente.\n",
      "Narrado: Aten√ß√£o: car a 0.0 metros √† frente.\n",
      "üîä Aten√ß√£o: car a 0.0 metros √† frente.\n",
      "Narrado: Aten√ß√£o: car a 0.0 metros √† frente.\n",
      "üîä Aten√ß√£o: person a 0.0 metros √† frente.\n",
      "Narrado: Aten√ß√£o: person a 0.0 metros √† frente.\n",
      "üîä Aten√ß√£o: car a 0.0 metros √† frente.\n",
      "Narrado: Aten√ß√£o: car a 0.0 metros √† frente.\n",
      "üîä Aten√ß√£o: car a 0.0 metros √† frente.\n",
      "Narrado: Aten√ß√£o: car a 0.0 metros √† frente.\n",
      "üîä Aten√ß√£o: car a 0.0 metros √† frente.\n",
      "Narrado: Aten√ß√£o: car a 0.0 metros √† frente.\n",
      "üîä Aten√ß√£o: car a 0.0 metros √† frente.\n",
      "Narrado: Aten√ß√£o: car a 0.0 metros √† frente.\n",
      "üîä Aten√ß√£o: car a 0.0 metros √† frente.\n",
      "Narrado: Aten√ß√£o: car a 0.0 metros √† frente.\n",
      "üîä Aten√ß√£o: car a 0.0 metros √† frente.\n",
      "Narrado: Aten√ß√£o: car a 0.0 metros √† frente.\n",
      "üîä Aten√ß√£o: car a 0.0 metros √† frente.\n",
      "Narrado: Aten√ß√£o: car a 0.0 metros √† frente.\n",
      "üîä Aten√ß√£o: car a 0.0 metros √† frente.\n",
      "Narrado: Aten√ß√£o: car a 0.0 metros √† frente.\n",
      "üîä Aten√ß√£o: car a 0.0 metros √† frente.\n",
      "Narrado: Aten√ß√£o: car a 0.0 metros √† frente.\n",
      "üîä Aten√ß√£o: car a 0.0 metros √† frente.\n",
      "Narrado: Aten√ß√£o: car a 0.0 metros √† frente.\n",
      "üîä Aten√ß√£o: car a 0.0 metros √† frente.\n",
      "Narrado: Aten√ß√£o: car a 0.0 metros √† frente.\n",
      "üîä Aten√ß√£o: car a 0.1 metros √† frente.\n",
      "Narrado: Aten√ß√£o: car a 0.1 metros √† frente.\n",
      "üîä Aten√ß√£o: car a 0.0 metros √† frente.\n",
      "Narrado: Aten√ß√£o: car a 0.0 metros √† frente.\n",
      "üîä Aten√ß√£o: car a 0.1 metros √† frente.\n",
      "Narrado: Aten√ß√£o: car a 0.1 metros √† frente.\n",
      "üîä Aten√ß√£o: car a 0.1 metros √† frente.\n",
      "Narrado: Aten√ß√£o: car a 0.1 metros √† frente.\n",
      "üîä Aten√ß√£o: car a 0.0 metros √† frente.\n",
      "Narrado: Aten√ß√£o: car a 0.0 metros √† frente.\n",
      "üîä Aten√ß√£o: car a 0.0 metros √† frente.\n",
      "Narrado: Aten√ß√£o: car a 0.0 metros √† frente.\n",
      "üîä Aten√ß√£o: car a 0.1 metros √† frente.\n",
      "Narrado: Aten√ß√£o: car a 0.1 metros √† frente.\n",
      "üîä Aten√ß√£o: car a 0.0 metros √† frente.\n",
      "Narrado: Aten√ß√£o: car a 0.0 metros √† frente.\n",
      "üîä Aten√ß√£o: car a 0.1 metros √† frente.\n",
      "Narrado: Aten√ß√£o: car a 0.1 metros √† frente.\n",
      "üîä Aten√ß√£o: car a 0.1 metros √† frente.\n",
      "Narrado: Aten√ß√£o: car a 0.1 metros √† frente.\n",
      "üîä Aten√ß√£o: car a 0.0 metros √† frente.\n",
      "Narrado: Aten√ß√£o: car a 0.0 metros √† frente.\n",
      "üîä Aten√ß√£o: car a 0.0 metros √† frente.\n",
      "Narrado: Aten√ß√£o: car a 0.0 metros √† frente.\n",
      "üîä Aten√ß√£o: car a 0.0 metros √† frente.\n",
      "Narrado: Aten√ß√£o: car a 0.0 metros √† frente.\n",
      "üîä Aten√ß√£o: car a 0.0 metros √† frente.\n",
      "Narrado: Aten√ß√£o: car a 0.0 metros √† frente.\n",
      "üîä Aten√ß√£o: car a 0.1 metros √† frente.\n",
      "Narrado: Aten√ß√£o: car a 0.1 metros √† frente.\n",
      "üîä Aten√ß√£o: car a 0.0 metros √† frente.\n",
      "Narrado: Aten√ß√£o: car a 0.0 metros √† frente.\n",
      "üîä Aten√ß√£o: car a 0.0 metros √† frente.\n",
      "Narrado: Aten√ß√£o: car a 0.0 metros √† frente.\n",
      "üîä Aten√ß√£o: car a 0.0 metros √† frente.\n",
      "Narrado: Aten√ß√£o: car a 0.0 metros √† frente.\n",
      "üîä Aten√ß√£o: car a 0.0 metros √† frente.\n",
      "Narrado: Aten√ß√£o: car a 0.0 metros √† frente.\n",
      "üîä Aten√ß√£o: car a 0.0 metros √† frente.\n",
      "Narrado: Aten√ß√£o: car a 0.0 metros √† frente.\n",
      "üîä Aten√ß√£o: car a 0.0 metros √† frente.\n",
      "Narrado: Aten√ß√£o: car a 0.0 metros √† frente.\n",
      "üîä Aten√ß√£o: car a 0.0 metros √† frente.\n",
      "Narrado: Aten√ß√£o: car a 0.0 metros √† frente.\n",
      "üîä Aten√ß√£o: car a 0.1 metros √† frente.\n",
      "Narrado: Aten√ß√£o: car a 0.1 metros √† frente.\n",
      "üîä Aten√ß√£o: person a 0.0 metros √† frente.\n",
      "Narrado: Aten√ß√£o: person a 0.0 metros √† frente.\n",
      "üîä Aten√ß√£o: car a 0.0 metros √† frente.\n",
      "Narrado: Aten√ß√£o: car a 0.0 metros √† frente.\n",
      "üîä Aten√ß√£o: car a 0.1 metros √† frente.\n",
      "Narrado: Aten√ß√£o: car a 0.1 metros √† frente.\n",
      "üîä Aten√ß√£o: person a 0.0 metros √† frente.\n",
      "Narrado: Aten√ß√£o: person a 0.0 metros √† frente.\n",
      "üîä Aten√ß√£o: car a 0.1 metros √† frente.\n",
      "üîä Aten√ß√£o: person a 0.0 metros √† frente.\n",
      "Narrado: Aten√ß√£o: car a 0.1 metros √† frente.\n",
      "üîä Aten√ß√£o: car a 0.0 metros √† frente.\n",
      "üîä Aten√ß√£o: person a 0.0 metros √† frente.\n",
      "Narrado: Aten√ß√£o: person a 0.0 metros √† frente.\n",
      "üîä Aten√ß√£o: bench a 0.0 metros √† frente.\n",
      "üîä Aten√ß√£o: car a 0.0 metros √† frente.\n",
      "Narrado: Aten√ß√£o: car a 0.0 metros √† frente.\n",
      "üîä Aten√ß√£o: person a 0.0 metros √† frente.\n",
      "üîä Aten√ß√£o: bench a 0.0 metros √† frente.\n",
      "üîä Aten√ß√£o: car a 0.0 metros √† frente.\n",
      "Narrado: Aten√ß√£o: person a 0.0 metros √† frente.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 123\u001b[0m\n\u001b[0;32m    118\u001b[0m cv2\u001b[38;5;241m.\u001b[39mrectangle(frame, (x1_roi, y1_roi), (x2_roi, y2_roi), (\u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    120\u001b[0m \u001b[38;5;66;03m########################################\u001b[39;00m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;66;03m# DETEC√á√ÉO DE OBJETOS (YOLO)\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;66;03m########################################\u001b[39;00m\n\u001b[1;32m--> 123\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;66;03m########################################\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;66;03m# PROFUNDIDADE (MiDaS)\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;66;03m########################################\u001b[39;00m\n\u001b[0;32m    128\u001b[0m input_batch \u001b[38;5;241m=\u001b[39m transform(frame)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\ultralytics\\engine\\model.py:187\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, source, stream, **kwargs)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    160\u001b[0m     source: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m Path \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m Image\u001b[38;5;241m.\u001b[39mImage \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mtuple\u001b[39m \u001b[38;5;241m|\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray \u001b[38;5;241m|\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    161\u001b[0m     stream: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    163\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[0;32m    164\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;124;03m    Alias for the predict method, enabling the model instance to be callable for predictions.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;124;03m        ...     print(f\"Detected {len(r)} objects in image\")\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 187\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\ultralytics\\engine\\model.py:557\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[0;32m    555\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_prompts\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n\u001b[0;32m    556\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mset_prompts(prompts)\n\u001b[1;32m--> 557\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mpredict_cli(source\u001b[38;5;241m=\u001b[39msource) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\ultralytics\\engine\\predictor.py:229\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[1;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 229\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n",
      "File \u001b[1;32mc:\\Users\\gabrielgomes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\_contextlib.py:38\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m---> 38\u001b[0m         response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     41\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     42\u001b[0m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\ultralytics\\engine\\predictor.py:336\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[1;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m--> 336\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    337\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39membed:\n\u001b[0;32m    338\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m [preds] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(preds, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m preds  \u001b[38;5;66;03m# yield embedding tensors\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\ultralytics\\engine\\predictor.py:184\u001b[0m, in \u001b[0;36mBasePredictor.inference\u001b[1;34m(self, im, *args, **kwargs)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run inference on a given image using the specified model and arguments.\"\"\"\u001b[39;00m\n\u001b[0;32m    179\u001b[0m visualize \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    180\u001b[0m     increment_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_dir \u001b[38;5;241m/\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mstem, mkdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mvisualize \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_type\u001b[38;5;241m.\u001b[39mtensor)\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    183\u001b[0m )\n\u001b[1;32m--> 184\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gabrielgomes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gabrielgomes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\ultralytics\\nn\\autobackend.py:640\u001b[0m, in \u001b[0;36mAutoBackend.forward\u001b[1;34m(self, im, augment, visualize, embed, **kwargs)\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;66;03m# PyTorch\u001b[39;00m\n\u001b[0;32m    639\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpt \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn_module:\n\u001b[1;32m--> 640\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    642\u001b[0m \u001b[38;5;66;03m# TorchScript\u001b[39;00m\n\u001b[0;32m    643\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjit:\n",
      "File \u001b[1;32mc:\\Users\\gabrielgomes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gabrielgomes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\ultralytics\\nn\\tasks.py:139\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[1;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\ultralytics\\nn\\tasks.py:157\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[1;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_augment(x)\n\u001b[1;32m--> 157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\ultralytics\\nn\\tasks.py:180\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[1;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[1;32m--> 180\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[0;32m    181\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(x \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "File \u001b[1;32mc:\\Users\\gabrielgomes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gabrielgomes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\ultralytics\\nn\\modules\\block.py:319\u001b[0m, in \u001b[0;36mC2f.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    317\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x)\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    318\u001b[0m y\u001b[38;5;241m.\u001b[39mextend(m(y[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm)\n\u001b[1;32m--> 319\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Narrado: Aten√ß√£o: bench a 0.0 metros √† frente.\n",
      "Narrado: Aten√ß√£o: car a 0.0 metros √† frente.\n",
      "Narrado: Aten√ß√£o: person a 0.0 metros √† frente.\n",
      "Narrado: Aten√ß√£o: bench a 0.0 metros √† frente.\n",
      "Narrado: Aten√ß√£o: car a 0.0 metros √† frente.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import pyttsx3\n",
    "import time\n",
    "import queue\n",
    "import threading\n",
    "from ultralytics import YOLO\n",
    "\n",
    "############################################\n",
    "# 1) CONFIGURA√á√ÉO DOS MODELOS\n",
    "############################################\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Modelo YOLOv8 ‚Äî detec√ß√£o de objetos\n",
    "model = YOLO('yolov8s.pt')\n",
    "\n",
    "# Modelo MiDaS ‚Äî estimativa de profundidade monocular\n",
    "midas = torch.hub.load('intel-isl/MiDaS', 'MiDaS_small', trust_repo=True).to(device).eval()\n",
    "transform = torch.hub.load('intel-isl/MiDaS', 'transforms', trust_repo=True).small_transform\n",
    "\n",
    "############################################\n",
    "# 2) CONFIGURA√á√ÉO DE CLASSES E ROI\n",
    "############################################\n",
    "CLASSES_UTEIS = ['person', 'bench', 'bicycle', 'car', 'chair', 'stop sign']\n",
    "METER_SCALE = 4.0  # fator aproximado para converter profundidade em metros\n",
    "\n",
    "# ROI (Zona de Interesse Frontal)\n",
    "ROI_X1, ROI_X2 = 0.15, 0.75\n",
    "ROI_Y1, ROI_Y2 = 0.35, 0.75\n",
    "\n",
    "############################################\n",
    "# 3) CONFIGURA√á√ÉO DO TTS (NARRA√á√ÉO)\n",
    "############################################\n",
    "# tts = pyttsx3.init(driverName='sapi5')  # para Windows\n",
    "# tts.setProperty('rate', 170)  # velocidade da fala\n",
    "\n",
    "# Controle de rate-limit por classe\n",
    "ultima_fala_por_classe = {}\n",
    "INTERVALO_FALA = 5.0  # segundos entre mensagens da mesma classe\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# Configura√ß√£o do TTS (PT-BR, fila √∫nica)\n",
    "# ==============================\n",
    "\n",
    "speech_queue = queue.Queue()\n",
    "\n",
    "def tts_worker():\n",
    "    engine = pyttsx3.init() # object creation\n",
    "\n",
    "    # RATE\n",
    "    engine.setProperty('rate', 175)     # setting up new voice rate\n",
    "    # VOLUME\n",
    "    engine.setProperty('volume',1.0)        # setting up volume level  between 0 and 1\n",
    "\n",
    "    for v in engine.getProperty(\"voices\"):\n",
    "        if \"brazil\" in v.name.lower() or \"portugu\" in v.name.lower():\n",
    "            print(\"Voz selecionada:\", v.name)\n",
    "            engine.setProperty(\"voice\", v.id)\n",
    "            break\n",
    "\n",
    "    while True:\n",
    "        text = speech_queue.get()\n",
    "        if text is None:\n",
    "            break\n",
    "        try:\n",
    "            print(f\"Narrado: {text}\")\n",
    "            engine = pyttsx3.init()\n",
    "            engine.say(f\"{text}\")\n",
    "            engine.say(\".\")\n",
    "            engine.runAndWait()\n",
    "            engine.stop()\n",
    "        except Exception as e:\n",
    "            print(f\"Erro no TTS: {e}\")\n",
    "        finally:\n",
    "            speech_queue.task_done()\n",
    "            \n",
    "    engine.stop()\n",
    "    print(\"Thread TTS finalizada com seguran√ßa.\")\n",
    "\n",
    "threading.Thread(target=tts_worker, daemon=True).start()\n",
    "\n",
    "def speak(text: str):\n",
    "    \"\"\"Adiciona texto √† fila de fala\"\"\"\n",
    "    speech_queue.put(text.strip())\n",
    "\n",
    "\n",
    "def narrar_text(mensagem, classe):\n",
    "    \"\"\"Faz a narra√ß√£o, respeitando intervalo m√≠nimo por classe.\"\"\"\n",
    "    global ultima_fala_por_classe\n",
    "    agora = time.time()\n",
    "    ultima = ultima_fala_por_classe.get(classe, 0)\n",
    "    if agora - ultima > INTERVALO_FALA:\n",
    "        print(\"üîä\", mensagem)\n",
    "        speak(mensagem)\n",
    "        ultima_fala_por_classe[classe] = agora\n",
    "\n",
    "\n",
    "############################################\n",
    "# 4) LOOP PRINCIPAL\n",
    "############################################\n",
    "video_path = r\"C:/codes/unicamp/MC949/T3/videos/VID_20251014_120019333.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    height, width, _ = frame.shape\n",
    "\n",
    "    # Desenha ROI\n",
    "    x1_roi = int(width * ROI_X1)\n",
    "    x2_roi = int(width * ROI_X2)\n",
    "    y1_roi = int(height * ROI_Y1)\n",
    "    y2_roi = int(height * ROI_Y2)\n",
    "    cv2.rectangle(frame, (x1_roi, y1_roi), (x2_roi, y2_roi), (255, 255, 0), 2)\n",
    "\n",
    "    ########################################\n",
    "    # DETEC√á√ÉO DE OBJETOS (YOLO)\n",
    "    ########################################\n",
    "    results = model(frame, verbose=False)\n",
    "\n",
    "    ########################################\n",
    "    # PROFUNDIDADE (MiDaS)\n",
    "    ########################################\n",
    "    input_batch = transform(frame).to(device)\n",
    "    with torch.no_grad():\n",
    "        depth = midas(input_batch)\n",
    "        depth = torch.nn.functional.interpolate(\n",
    "            depth.unsqueeze(1),\n",
    "            size=frame.shape[:2],\n",
    "            mode='bilinear',\n",
    "            align_corners=False\n",
    "        ).squeeze().cpu().numpy()\n",
    "\n",
    "    ########################################\n",
    "    # AN√ÅLISE DE OBJETOS\n",
    "    ########################################\n",
    "    for result in results:\n",
    "        for box in result.boxes:\n",
    "            cls = model.names[int(box.cls)]\n",
    "            conf = float(box.conf)\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "\n",
    "            if cls not in CLASSES_UTEIS or conf < 0.5:\n",
    "                continue\n",
    "\n",
    "            # Centro da detec√ß√£o\n",
    "            cx, cy = (x1 + x2) // 2, (y1 + y2) // 2\n",
    "\n",
    "            # Verifica se est√° na ROI\n",
    "            if not (x1_roi < cx < x2_roi and y1_roi < cy < y2_roi):\n",
    "                continue\n",
    "\n",
    "            # Estima dist√¢ncia\n",
    "            obj_depth = np.median(depth[y1:y2, x1:x2])\n",
    "            distancia_m = METER_SCALE / max(obj_depth, 0.1)\n",
    "\n",
    "            # Exibe na tela\n",
    "            texto = f\"{cls} {distancia_m:.1f}m\"\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, texto, (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "\n",
    "            ########################################\n",
    "            # NARRA√á√ÉO (op√ß√£o A)\n",
    "            ########################################\n",
    "            if distancia_m < 2.0:\n",
    "                narrar_text(f\"Aten√ß√£o: {cls} a {distancia_m:.1f} metros √† frente.\", cls)\n",
    "            elif distancia_m < 4.0:\n",
    "                narrar_text(f\"{cls} a {distancia_m:.1f} metros. Siga em frente.\", cls)\n",
    "\n",
    "    ########################################\n",
    "    # TELEMETRIA OPCIONAL (FPS)\n",
    "    ########################################\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    cv2.putText(frame, f\"FPS: {fps:.1f}\", (20, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"Percep√ß√£o + Narra√ß√£o Cont√≠nua\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "speech_queue.put(None)\n",
    "speech_queue.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfdd3f9f-818a-424b-bbe1-be6a05b59422",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\gabrielgomes/.cache\\torch\\hub\\intel-isl_MiDaS_master\n",
      "c:\\Users\\gabrielgomes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\timm\\models\\layers\\__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights:  None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\gabrielgomes/.cache\\torch\\hub\\rwightman_gen-efficientnet-pytorch_master\n",
      "Using cache found in C:\\Users\\gabrielgomes/.cache\\torch\\hub\\intel-isl_MiDaS_master\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'queue' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 33\u001b[0m\n\u001b[0;32m     27\u001b[0m ROI_Y1, ROI_Y2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.35\u001b[39m, \u001b[38;5;241m0.75\u001b[39m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# ==============================\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Configura√ß√£o do TTS (PT-BR, fila √∫nica)\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# ==============================\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m speech_queue \u001b[38;5;241m=\u001b[39m \u001b[43mqueue\u001b[49m\u001b[38;5;241m.\u001b[39mQueue()\n\u001b[0;32m     34\u001b[0m ultima_fala_por_classe \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     35\u001b[0m INTERVALO_FALA \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5.0\u001b[39m  \u001b[38;5;66;03m# segundos entre mensagens da mesma classe\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'queue' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import pyttsx3\n",
    "import time\n",
    "from ultralytics import YOLO\n",
    "\n",
    "############################################\n",
    "# 1) CONFIGURA√á√ÉO DOS MODELOS\n",
    "############################################\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# YOLOv8 para detec√ß√£o\n",
    "model = YOLO('yolov8s.pt')\n",
    "\n",
    "# MiDaS para profundidade\n",
    "midas = torch.hub.load('intel-isl/MiDaS', 'MiDaS_small', trust_repo=True).to(device).eval()\n",
    "transform = torch.hub.load('intel-isl/MiDaS', 'transforms', trust_repo=True).small_transform\n",
    "\n",
    "############################################\n",
    "# 2) CONFIGURA√á√ÉO DE CLASSES E ROI\n",
    "############################################\n",
    "CLASSES_UTEIS = ['person', 'bench', 'bicycle', 'car', 'chair', 'stop sign']\n",
    "METER_SCALE = 4.0\n",
    "\n",
    "ROI_X1, ROI_X2 = 0.15, 0.75\n",
    "ROI_Y1, ROI_Y2 = 0.35, 0.75\n",
    "\n",
    "# ==============================\n",
    "# Configura√ß√£o do TTS (PT-BR, fila √∫nica)\n",
    "# ==============================\n",
    "\n",
    "speech_queue = queue.Queue()\n",
    "ultima_fala_por_classe = {}\n",
    "INTERVALO_FALA = 5.0  # segundos entre mensagens da mesma classe\n",
    "\n",
    "def tts_worker():\n",
    "    engine = pyttsx3.init() # object creation\n",
    "\n",
    "    # RATE\n",
    "    engine.setProperty('rate', 275)     # setting up new voice rate\n",
    "    # VOLUME\n",
    "    engine.setProperty('volume',1.0)        # setting up volume level  between 0 and 1\n",
    "\n",
    "    for v in engine.getProperty(\"voices\"):\n",
    "        if \"brazil\" in v.name.lower() or \"portugu\" in v.name.lower():\n",
    "            print(\"Voz selecionada:\", v.name)\n",
    "            engine.setProperty(\"voice\", v.id)\n",
    "            break\n",
    "\n",
    "    while True:\n",
    "        text = speech_queue.get()\n",
    "        if text is None:\n",
    "            break\n",
    "        try:\n",
    "            print(f\"Narrado: {text}\")\n",
    "            engine = pyttsx3.init()\n",
    "            engine.say(f\"{text}\")\n",
    "            engine.say(\".\")\n",
    "            engine.runAndWait()\n",
    "            engine.stop()\n",
    "        except Exception as e:\n",
    "            print(f\"Erro no TTS: {e}\")\n",
    "        finally:\n",
    "            speech_queue.task_done()\n",
    "            \n",
    "    engine.stop()\n",
    "    print(\"Thread TTS finalizada com seguran√ßa.\")\n",
    "\n",
    "threading.Thread(target=tts_worker, daemon=True).start()\n",
    "\n",
    "def speak(text: str):\n",
    "    \"\"\"Adiciona texto √† fila de fala\"\"\"\n",
    "    speech_queue.put(text.strip())\n",
    "\n",
    "\n",
    "def narrar_text(mensagem, classe):\n",
    "    \"\"\"Faz a narra√ß√£o, respeitando intervalo m√≠nimo por classe.\"\"\"\n",
    "    global ultima_fala_por_classe\n",
    "    agora = time.time()\n",
    "    ultima = ultima_fala_por_classe.get(classe, 0)\n",
    "    if agora - ultima > INTERVALO_FALA:\n",
    "        print(\"üîä\", mensagem)\n",
    "        speak(mensagem)\n",
    "        ultima_fala_por_classe[classe] = agora\n",
    "\n",
    "############################################\n",
    "# 4) LOOP PRINCIPAL\n",
    "############################################\n",
    "video_path = r\"C:/codes/unicamp/MC949/T3/videos/VID_20251014_120019333.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    height, width, _ = frame.shape\n",
    "\n",
    "    # ROI\n",
    "    x1_roi = int(width * ROI_X1)\n",
    "    x2_roi = int(width * ROI_X2)\n",
    "    y1_roi = int(height * ROI_Y1)\n",
    "    y2_roi = int(height * ROI_Y2)\n",
    "    cv2.rectangle(frame, (x1_roi, y1_roi), (x2_roi, y2_roi), (255, 255, 0), 2)\n",
    "\n",
    "    # YOLO detec√ß√£o\n",
    "    results = model(frame, verbose=False)\n",
    "\n",
    "    # MiDaS profundidade\n",
    "    input_batch = transform(frame).to(device)\n",
    "    with torch.no_grad():\n",
    "        depth = midas(input_batch)\n",
    "        depth = torch.nn.functional.interpolate(\n",
    "            depth.unsqueeze(1),\n",
    "            size=frame.shape[:2],\n",
    "            mode='bilinear',\n",
    "            align_corners=False\n",
    "        ).squeeze().cpu().numpy()\n",
    "\n",
    "    for result in results:\n",
    "        for box in result.boxes:\n",
    "            cls = model.names[int(box.cls)]\n",
    "            conf = float(box.conf)\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "\n",
    "            if cls not in CLASSES_UTEIS or conf < 0.5:\n",
    "                continue\n",
    "\n",
    "            cx, cy = (x1 + x2) // 2, (y1 + y2) // 2\n",
    "            if not (x1_roi < cx < x2_roi and y1_roi < cy < y2_roi):\n",
    "                continue\n",
    "\n",
    "            # Dire√ß√£o (esquerda / direita / frente)\n",
    "            largura_roi = x2_roi - x1_roi\n",
    "            pos_relativa = (cx - x1_roi) / largura_roi\n",
    "            if pos_relativa < 0.33:\n",
    "                direcao = \"√† esquerda\"\n",
    "            elif pos_relativa > 0.66:\n",
    "                direcao = \"√† direita\"\n",
    "            else:\n",
    "                direcao = \"√† frente\"\n",
    "\n",
    "            # Dist√¢ncia estimada\n",
    "            obj_depth = np.median(depth[y1:y2, x1:x2])\n",
    "            distancia_m = METER_SCALE / max(obj_depth, 0.1)\n",
    "\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            texto = f\"{cls} {distancia_m:.1f}m {direcao}\"\n",
    "            cv2.putText(frame, texto, (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "\n",
    "            # Narra√ß√£o com dire√ß√£o\n",
    "            if distancia_m < 2.0:\n",
    "                narrar_text(f\"Aten√ß√£o: {cls} a {distancia_m:.1f} metros {direcao}.\", cls)\n",
    "            elif distancia_m < 4.0:\n",
    "                narrar_text(f\"{cls} a {distancia_m:.1f} metros {direcao}.\", cls)\n",
    "\n",
    "    # FPS\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    cv2.putText(frame, f\"FPS: {fps:.1f}\", (20, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"Percep√ß√£o + Narra√ß√£o Direcional\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "speech_queue.put(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "290f720f-b412-4b8d-ae8c-5077b9c51589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicializando TTS...\n",
      "\n",
      "=== VOZES DISPON√çVEIS ===\n",
      "HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Speech\\Voices\\Tokens\\TTS_MS_PT-BR_MARIA_11.0 - Microsoft Maria Desktop - Portuguese(Brazil)\n",
      "HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Speech\\Voices\\Tokens\\TTS_MS_EN-US_ZIRA_11.0 - Microsoft Zira Desktop - English (United States)\n",
      "‚úÖ Fim do teste.\n"
     ]
    }
   ],
   "source": [
    "import pyttsx3\n",
    "\n",
    "print(\"Inicializando TTS...\")\n",
    "tts = pyttsx3.init(driverName='sapi5')\n",
    "\n",
    "print(\"\\n=== VOZES DISPON√çVEIS ===\")\n",
    "for v in tts.getProperty('voices'):\n",
    "    print(v.id, \"-\", v.name)\n",
    "\n",
    "tts.setProperty('rate', 170)\n",
    "tts.say(\"Teste de voz. Se voc√™ ouviu isto, o T T S est√° funcionando.\")\n",
    "tts.runAndWait()\n",
    "print(\"‚úÖ Fim do teste.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de543979-b0db-455e-a1c2-c02c07ac5c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gTTS\n",
      "  Downloading gTTS-2.5.4-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting playsound==1.2.2\n",
      "  Downloading playsound-1.2.2-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\lilia\\onedrive\\estudo\\visao_computacional\\t3\\venv\\lib\\site-packages (from gTTS) (2.32.5)\n",
      "Collecting click<8.2,>=7.1 (from gTTS)\n",
      "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\lilia\\onedrive\\estudo\\visao_computacional\\t3\\venv\\lib\\site-packages (from click<8.2,>=7.1->gTTS) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\lilia\\onedrive\\estudo\\visao_computacional\\t3\\venv\\lib\\site-packages (from requests<3,>=2.27->gTTS) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lilia\\onedrive\\estudo\\visao_computacional\\t3\\venv\\lib\\site-packages (from requests<3,>=2.27->gTTS) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lilia\\onedrive\\estudo\\visao_computacional\\t3\\venv\\lib\\site-packages (from requests<3,>=2.27->gTTS) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lilia\\onedrive\\estudo\\visao_computacional\\t3\\venv\\lib\\site-packages (from requests<3,>=2.27->gTTS) (2025.10.5)\n",
      "Downloading playsound-1.2.2-py2.py3-none-any.whl (6.0 kB)\n",
      "Downloading gTTS-2.5.4-py3-none-any.whl (29 kB)\n",
      "Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Installing collected packages: playsound, click, gTTS\n",
      "\n",
      "   -------------------------- ------------- 2/3 [gTTS]\n",
      "   ---------------------------------------- 3/3 [gTTS]\n",
      "\n",
      "Successfully installed click-8.1.8 gTTS-2.5.4 playsound-1.2.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~umpy (C:\\Users\\lilia\\OneDrive\\Estudo\\Visao_Computacional\\T3\\venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (C:\\Users\\lilia\\OneDrive\\Estudo\\Visao_Computacional\\T3\\venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (C:\\Users\\lilia\\OneDrive\\Estudo\\Visao_Computacional\\T3\\venv\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install gTTS playsound==1.2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad31dff-024b-4911-af31-d8d8a7ab135b",
   "metadata": {},
   "source": [
    "### N√£o est√° saindo a narra√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c18dcb8-a595-4449-9cea-15db8c5777d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voz selecionada: Microsoft Maria Desktop - Portuguese(Brazil)\n",
      "üîä Obst√°culo √† frente. Desvie √† direita.\n",
      "Narrado: Obst√°culo √† frente. Desvie √† direita.\n",
      "üîä Obst√°culo √† frente. Desvie √† direita.\n",
      "Narrado: Obst√°culo √† frente. Desvie √† direita.\n",
      "üîä Obst√°culo √† frente. Desvie √† direita.\n",
      "Narrado: Obst√°culo √† frente. Desvie √† direita.\n",
      "üîä Obst√°culo √† frente. Desvie √† direita.\n",
      "Narrado: Obst√°culo √† frente. Desvie √† direita.\n",
      "üîä Obst√°culo √† frente. Desvie √† direita.\n",
      "Narrado: Obst√°culo √† frente. Desvie √† direita.\n",
      "üîä Obst√°culo √† frente. Desvie √† direita.\n",
      "Narrado: Obst√°culo √† frente. Desvie √† direita.\n",
      "üîä Obst√°culo √† frente. Desvie √† direita.\n",
      "Narrado: Obst√°culo √† frente. Desvie √† direita.\n",
      "üîä Obst√°culo √† frente. Desvie √† direita.\n",
      "Narrado: Obst√°culo √† frente. Desvie √† direita.\n",
      "üîä Obst√°culo √† frente. Desvie √† direita.\n",
      "Narrado: Obst√°culo √† frente. Desvie √† direita.\n",
      "üîä Obst√°culo √† frente. Desvie √† direita.\n",
      "Narrado: Obst√°culo √† frente. Desvie √† direita.\n",
      "üîä Obst√°culo √† frente. Desvie √† direita.\n",
      "Narrado: Obst√°culo √† frente. Desvie √† direita.\n",
      "üîä Obst√°culo √† frente. Desvie √† direita.\n",
      "Narrado: Obst√°culo √† frente. Desvie √† direita.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread TTS finalizada com seguran√ßa.\n"
     ]
    }
   ],
   "source": [
    "##############################################\n",
    "# ETAPA 4 ‚Äî NARRA√á√ÉO & UX (funcional no Jupyter)\n",
    "##############################################\n",
    "\n",
    "# from gtts import gTTS\n",
    "# from playsound import playsound\n",
    "import tempfile\n",
    "import time\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# ===========================================\n",
    "# CONFIGURA√á√ÉO DE NARRA√á√ÉO (TTS)\n",
    "# ===========================================\n",
    "# ultima_narracao = 0\n",
    "# intervalo_minimo = 3.0  # segundos entre falas para evitar \"spam\"\n",
    "\n",
    "# def narrar(mensagem, prioridade=False):\n",
    "#     global ultima_narracao\n",
    "#     agora = time.time()\n",
    "\n",
    "#     # Se for alerta cr√≠tico, fala mesmo que o tempo m√≠nimo n√£o tenha passado\n",
    "#     if (agora - ultima_narracao) < intervalo_minimo and not prioridade:\n",
    "#         return\n",
    "\n",
    "#     print(f\"üîä {mensagem}\")\n",
    "#     try:\n",
    "#         with tempfile.NamedTemporaryFile(delete=True, suffix=\".mp3\") as f:\n",
    "#             tts = gTTS(mensagem, lang='pt-br')\n",
    "#             tts.save(f.name)\n",
    "#             playsound(f.name)\n",
    "#         ultima_narracao = agora\n",
    "#     except Exception as e:\n",
    "#         print(f\"[ERRO TTS] {e}\")\n",
    "        \n",
    "# ==============================\n",
    "# Configura√ß√£o do TTS (PT-BR, fila √∫nica)\n",
    "# ==============================\n",
    "\n",
    "speech_queue = queue.Queue()\n",
    "ultima_fala_por_classe = {}\n",
    "INTERVALO_FALA = 5.0  # segundos entre mensagens da mesma classe\n",
    "\n",
    "def tts_worker():\n",
    "    engine = pyttsx3.init() # object creation\n",
    "\n",
    "    # RATE\n",
    "    engine.setProperty('rate', 175)     # setting up new voice rate\n",
    "    # VOLUME\n",
    "    engine.setProperty('volume',1.0)        # setting up volume level  between 0 and 1\n",
    "\n",
    "    for v in engine.getProperty(\"voices\"):\n",
    "        if \"brazil\" in v.name.lower() or \"portugu\" in v.name.lower():\n",
    "            print(\"Voz selecionada:\", v.name)\n",
    "            engine.setProperty(\"voice\", v.id)\n",
    "            break\n",
    "\n",
    "    while True:\n",
    "        text = speech_queue.get()\n",
    "        if text is None:\n",
    "            break\n",
    "        try:\n",
    "            print(f\"Narrado: {text}\")\n",
    "            engine = pyttsx3.init()\n",
    "            engine.say(f\"{text}\")\n",
    "            engine.say(\".\")\n",
    "            engine.runAndWait()\n",
    "            engine.stop()\n",
    "        except Exception as e:\n",
    "            print(f\"Erro no TTS: {e}\")\n",
    "        finally:\n",
    "            speech_queue.task_done()\n",
    "            \n",
    "    engine.stop()\n",
    "    print(\"Thread TTS finalizada com seguran√ßa.\")\n",
    "\n",
    "threading.Thread(target=tts_worker, daemon=True).start()\n",
    "\n",
    "def speak(text: str):\n",
    "    \"\"\"Adiciona texto √† fila de fala\"\"\"\n",
    "    speech_queue.put(text.strip())\n",
    "\n",
    "\n",
    "def narrar_text(mensagem, classe):\n",
    "    \"\"\"Faz a narra√ß√£o, respeitando intervalo m√≠nimo por classe.\"\"\"\n",
    "    global ultima_fala_por_classe\n",
    "    agora = time.time()\n",
    "    ultima = ultima_fala_por_classe.get(classe, 0)\n",
    "    if agora - ultima > INTERVALO_FALA:\n",
    "        print(\"üîä\", mensagem)\n",
    "        speak(mensagem)\n",
    "        ultima_fala_por_classe[classe] = agora\n",
    "\n",
    "# ===========================================\n",
    "# FUN√á√ïES AUXILIARES DE DETEC√á√ÉO E PROFUNDIDADE\n",
    "# ===========================================\n",
    "\n",
    "def estimar_distancia(mask, depth_map):\n",
    "    \"\"\"Retorna a dist√¢ncia m√©dia (em escala relativa) de um objeto\"\"\"\n",
    "    if mask is None or np.sum(mask) == 0:\n",
    "        return None\n",
    "    profundidades = depth_map[mask > 0]\n",
    "    return float(np.median(profundidades))\n",
    "\n",
    "def avaliar_risco(distancia, posicao_roi):\n",
    "    \"\"\"Heur√≠stica simples de risco\"\"\"\n",
    "    if distancia is None:\n",
    "        return \"sem risco\"\n",
    "    if distancia < 0.3:\n",
    "        return \"‚ö†Ô∏è Colis√£o iminente\"\n",
    "    elif distancia < 0.6:\n",
    "        return \"üö∂ Obst√°culo pr√≥ximo\"\n",
    "    elif posicao_roi == \"frente\":\n",
    "        return \"üü¢ Caminho livre\"\n",
    "    else:\n",
    "        return \"seguro\"\n",
    "\n",
    "# ===========================================\n",
    "# LOOP PRINCIPAL (exemplo)\n",
    "# ===========================================\n",
    "\n",
    "video_path = r\"C:/codes/unicamp/MC949/T3/videos/VID_20251014_120019333.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "fps_time = time.time()\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Simula profundidade com valores aleat√≥rios (substitua pela sa√≠da real do MiDaS)\n",
    "    depth_map = np.random.rand(frame.shape[0], frame.shape[1])\n",
    "\n",
    "    # Simula detec√ß√£o de pessoa no centro\n",
    "    mask = np.zeros_like(depth_map)\n",
    "    h, w = depth_map.shape\n",
    "    mask[h//3:2*h//3, w//3:2*w//3] = 1\n",
    "\n",
    "    distancia = estimar_distancia(mask, depth_map)\n",
    "    risco = avaliar_risco(distancia, \"frente\")\n",
    "\n",
    "    # Exemplo de narra√ß√£o\n",
    "    if \"Colis√£o\" in risco:\n",
    "        narrar_text(\"Aten√ß√£o! Obst√°culo √† frente!\", classe=\"default\")\n",
    "    elif \"pr√≥ximo\" in risco:\n",
    "        narrar_text(\"Obst√°culo √† frente. Desvie √† direita.\", classe=\"default\")\n",
    "    elif \"livre\" in risco:\n",
    "        narrar_text(\"Caminho livre.\", classe=\"default\")\n",
    "\n",
    "    # Telemetria na tela\n",
    "    fps = 1.0 / (time.time() - fps_time)\n",
    "    fps_time = time.time()\n",
    "    cv2.putText(frame, f\"{risco} - Dist√¢ncia: {distancia:.2f} - FPS: {fps:.1f}\",\n",
    "                (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"Detec√ß√£o com TTS\", frame)\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "speech_queue.put(None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b620fe87",
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_queue.put(None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
