{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4a51ec2-06d3-40c0-8cd9-a2604a3aff49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\gabrielgomes/.cache\\torch\\hub\\intel-isl_MiDaS_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights:  None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\gabrielgomes/.cache\\torch\\hub\\rwightman_gen-efficientnet-pytorch_master\n",
      "Using cache found in C:\\Users\\gabrielgomes/.cache\\torch\\hub\\intel-isl_MiDaS_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TTS] Falando: carro a 12,6 metros à esquerda.\n",
      "[TTS] Tempo usado: 3.11 segundos\n",
      "[TTS] Falando: carro a 25,2 metros à frente.\n",
      "[TTS] Tempo usado: 3.42 segundos\n",
      "[TTS] Falando: carro a 54,6 metros à frente.\n",
      "[TTS] Tempo usado: 3.52 segundos\n",
      "[TTS] Falando: carro a 28,1 metros à frente.\n",
      "[TTS] Tempo usado: 3.29 segundos\n",
      "[TTS] Falando: carro a 140,3 metros à frente.\n",
      "[TTS] Tempo usado: 3.56 segundos\n",
      "[TTS] Falando: carro a 52,6 metros à frente.\n",
      "[TTS] Tempo usado: 4.99 segundos\n",
      "[TTS] Falando: carro a 55,7 metros à frente.\n",
      "[TTS] Tempo usado: 3.65 segundos\n",
      "[TTS] Falando: carro a 49,8 metros à frente.\n",
      "[TTS] Tempo usado: 3.74 segundos\n",
      "[TTS] Falando: carro a 36,4 metros à frente.\n",
      "[TTS] Tempo usado: 3.56 segundos\n",
      "[TTS] Falando: pessoa a 23,6 metros à esquerda.\n",
      "[TTS] Tempo usado: 3.60 segundos\n",
      "[TTS] Falando: carro a 59,1 metros à esquerda.\n",
      "[TTS] Tempo usado: 3.63 segundos\n",
      "[TTS] Falando: carro a 33,7 metros à frente.\n",
      "[TTS] Tempo usado: 3.37 segundos\n",
      "[TTS] Falando: banco a 18,2 metros à direita.\n",
      "[TTS] Tempo usado: 3.52 segundos\n",
      "[TTS] Falando: carro a 24,7 metros à frente.\n",
      "[TTS] Tempo usado: 3.67 segundos\n",
      "[TTS] Falando: banco a 8,1 metros à frente.\n",
      "[TTS] Tempo usado: 2.73 segundos\n",
      "[TTS] Falando: carro a 22,6 metros à frente.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 252\u001b[0m\n\u001b[0;32m    249\u001b[0m         flow \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcalcOpticalFlowFarneback(prev_gray, gray, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m21\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m1.2\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    250\u001b[0m     prev_gray \u001b[38;5;241m=\u001b[39m gray\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m--> 252\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43myolo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    253\u001b[0m _auto_calibrate_scale(results, invdepth, frame\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m    255\u001b[0m candidates \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\ultralytics\\engine\\model.py:187\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, source, stream, **kwargs)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    160\u001b[0m     source: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m Path \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m Image\u001b[38;5;241m.\u001b[39mImage \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mtuple\u001b[39m \u001b[38;5;241m|\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray \u001b[38;5;241m|\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    161\u001b[0m     stream: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    163\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[0;32m    164\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;124;03m    Alias for the predict method, enabling the model instance to be callable for predictions.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;124;03m        ...     print(f\"Detected {len(r)} objects in image\")\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 187\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\ultralytics\\engine\\model.py:557\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[0;32m    555\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_prompts\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n\u001b[0;32m    556\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mset_prompts(prompts)\n\u001b[1;32m--> 557\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mpredict_cli(source\u001b[38;5;241m=\u001b[39msource) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\ultralytics\\engine\\predictor.py:229\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[1;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 229\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n",
      "File \u001b[1;32mc:\\Users\\gabrielgomes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\_contextlib.py:38\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m---> 38\u001b[0m         response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     41\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     42\u001b[0m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\ultralytics\\engine\\predictor.py:336\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[1;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m--> 336\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    337\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39membed:\n\u001b[0;32m    338\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m [preds] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(preds, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m preds  \u001b[38;5;66;03m# yield embedding tensors\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\ultralytics\\engine\\predictor.py:184\u001b[0m, in \u001b[0;36mBasePredictor.inference\u001b[1;34m(self, im, *args, **kwargs)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run inference on a given image using the specified model and arguments.\"\"\"\u001b[39;00m\n\u001b[0;32m    179\u001b[0m visualize \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    180\u001b[0m     increment_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_dir \u001b[38;5;241m/\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mstem, mkdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mvisualize \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_type\u001b[38;5;241m.\u001b[39mtensor)\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    183\u001b[0m )\n\u001b[1;32m--> 184\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gabrielgomes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gabrielgomes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\ultralytics\\nn\\autobackend.py:640\u001b[0m, in \u001b[0;36mAutoBackend.forward\u001b[1;34m(self, im, augment, visualize, embed, **kwargs)\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;66;03m# PyTorch\u001b[39;00m\n\u001b[0;32m    639\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpt \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn_module:\n\u001b[1;32m--> 640\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    642\u001b[0m \u001b[38;5;66;03m# TorchScript\u001b[39;00m\n\u001b[0;32m    643\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjit:\n",
      "File \u001b[1;32mc:\\Users\\gabrielgomes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gabrielgomes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\ultralytics\\nn\\tasks.py:139\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[1;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\ultralytics\\nn\\tasks.py:157\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[1;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_augment(x)\n\u001b[1;32m--> 157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\ultralytics\\nn\\tasks.py:180\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[1;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[1;32m--> 180\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[0;32m    181\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(x \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "File \u001b[1;32mc:\\Users\\gabrielgomes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gabrielgomes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\ultralytics\\nn\\modules\\conv.py:93\u001b[0m, in \u001b[0;36mConv.forward_fuse\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_fuse\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     84\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;124;03m    Apply convolution and activation without batch normalization.\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;124;03m        (torch.Tensor): Output tensor.\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\gabrielgomes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gabrielgomes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\gabrielgomes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    547\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 548\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gabrielgomes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:543\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[0;32m    533\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[0;32m    534\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    541\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[0;32m    542\u001b[0m     )\n\u001b[1;32m--> 543\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    544\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[0;32m    545\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import time\n",
    "import threading\n",
    "from queue import Queue\n",
    "import pyttsx3\n",
    "\n",
    "############################################\n",
    "# CONFIG PRINCIPAL\n",
    "############################################\n",
    "FAST_MODE = True\n",
    "FRAME_SKIP = 2\n",
    "USE_FLOW = False\n",
    "\n",
    "############################################\n",
    "# 1) MODELOS: YOLO + MiDaS\n",
    "############################################\n",
    "yolo = YOLO('yolov8n.pt')\n",
    "device = torch.device('cpu')\n",
    "\n",
    "midas = torch.hub.load('intel-isl/MiDaS', 'MiDaS_small', trust_repo=True).to(device).eval()\n",
    "transform = torch.hub.load('intel-isl/MiDaS', 'transforms', trust_repo=True).small_transform\n",
    "\n",
    "############################################\n",
    "# 2) CONFIGS DO PROJETO\n",
    "############################################\n",
    "CLASSES_UTEIS = ['person','bicycle','car','bench','chair','stop sign','potted plant']\n",
    "\n",
    "def get_roi(frame):\n",
    "    h, w = frame.shape[:2]\n",
    "    x1, x2 = int(w*0.10), int(w*0.70)\n",
    "    y1, y2 = int(h*0.35), int(h*0.75)\n",
    "    return (x1, y1, x2, y2)\n",
    "\n",
    "DIST_DANGER_M = 2.5\n",
    "FLOW_APPROACH_MIN = 0.6\n",
    "CENTER_BONUS = 0.15\n",
    "\n",
    "############################################\n",
    "# 3) FUNÇÕES UTILITÁRIAS (com calibração automática + debug visual)\n",
    "############################################\n",
    "\n",
    "FOV_H_DEG = 75.0\n",
    "PERSON_HEIGHT_M = 1.55\n",
    "CAMERA_HEIGHT_M = 1.0\n",
    "_dynamic_scale = 4.0\n",
    "_focal_px = None\n",
    "_last_debug_dist = None\n",
    "_calibrating_frames = 0\n",
    "\n",
    "def predict_depth(frame_bgr):\n",
    "    if FAST_MODE:\n",
    "        frame_bgr = cv2.resize(frame_bgr, (frame_bgr.shape[1]//2, frame_bgr.shape[0]//2))\n",
    "    img_rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)\n",
    "    inp = transform(img_rgb).to(device)\n",
    "    with torch.no_grad():\n",
    "        pred = midas(inp)\n",
    "        pred = torch.nn.functional.interpolate(\n",
    "            pred.unsqueeze(1),\n",
    "            size=img_rgb.shape[:2],\n",
    "            mode='bicubic',\n",
    "            align_corners=False\n",
    "        ).squeeze().cpu().numpy()\n",
    "    pred_norm = (pred - pred.min()) / (pred.max() - pred.min() + 1e-6)\n",
    "    pred_norm = cv2.medianBlur((pred_norm*255).astype(np.uint8), 5)\n",
    "    pred_norm = pred_norm.astype(np.float32)/255.0\n",
    "    if FAST_MODE:\n",
    "        pred_norm = cv2.resize(pred_norm, (frame_bgr.shape[1]*2, frame_bgr.shape[0]*2))\n",
    "    return pred_norm\n",
    "\n",
    "def _auto_calibrate_scale(yolo_results, invdepth, frame_shape):\n",
    "    \"\"\"\n",
    "    Ajusta automaticamente o fator de escala com base em uma pessoa detectada.\n",
    "    \"\"\"\n",
    "    global _dynamic_scale, _focal_px, _last_debug_dist, _calibrating_frames\n",
    "    h, w = frame_shape[:2]\n",
    "    if _focal_px is None:\n",
    "        _focal_px = (w / 2) / np.tan(np.deg2rad(FOV_H_DEG / 2))\n",
    "\n",
    "    person_boxes = []\n",
    "    for r in yolo_results:\n",
    "        for b in r.boxes:\n",
    "            cls = yolo.names[int(b.cls)]\n",
    "            if cls == 'person' and float(b.conf) > 0.6:\n",
    "                x1, y1, x2, y2 = map(int, b.xyxy[0])\n",
    "                cx = (x1 + x2) / 2\n",
    "                person_boxes.append((abs(cx - w/2), (x1, y1, x2, y2)))\n",
    "    if not person_boxes:\n",
    "        return\n",
    "\n",
    "    _, (x1, y1, x2, y2) = min(person_boxes, key=lambda t: t[0])\n",
    "    h_box = max(1, y2 - y1)\n",
    "\n",
    "    d_geom = (_focal_px * PERSON_HEIGHT_M) / h_box\n",
    "\n",
    "    box_depth = invdepth[y1:y2, x1:x2]\n",
    "    if box_depth.size == 0:\n",
    "        return\n",
    "    inv_med = float(np.median(box_depth))\n",
    "    d_midas = _dynamic_scale / max(inv_med, 1e-3)\n",
    "\n",
    "    scale_factor = d_geom / max(d_midas, 1e-3)\n",
    "    _dynamic_scale = 0.9 * _dynamic_scale + 0.1 * (_dynamic_scale * scale_factor)\n",
    "\n",
    "    _last_debug_dist = d_geom\n",
    "    _calibrating_frames += 1\n",
    "\n",
    "def invdepth_to_meters(invdepth):\n",
    "    inv = max(float(invdepth), 1e-3)\n",
    "    d_midas = _dynamic_scale / inv\n",
    "    dh = max(0.0, PERSON_HEIGHT_M - CAMERA_HEIGHT_M)\n",
    "    if d_midas > dh:\n",
    "        d_midas = (d_midas ** 2 - dh ** 2) ** 0.5\n",
    "    return d_midas\n",
    "\n",
    "def bbox_center(b):\n",
    "    x1, y1, x2, y2 = b\n",
    "    return (int((x1 + x2)//2), int((y1 + y2)//2))\n",
    "\n",
    "def mean_flow_in_bbox(flow, bbox):\n",
    "    if not USE_FLOW or flow is None:\n",
    "        return 0.0, 0.0, 0.0\n",
    "    x1, y1, x2, y2 = bbox\n",
    "    fx, fy = flow[y1:y2, x1:x2, 0], flow[y1:y2, x1:x2, 1]\n",
    "    if fx.size == 0:\n",
    "        return 0.0, 0.0, 0.0\n",
    "    mag = np.sqrt(fx*fx + fy*fy)\n",
    "    return float(np.mean(fx)), float(np.mean(fy)), float(np.mean(mag))\n",
    "\n",
    "def center_weight_in_roi(cx, cy, roi):\n",
    "    x1, y1, x2, y2 = roi\n",
    "    rx, ry = (x1 + x2)/2, (y1 + y2)/2\n",
    "    rw, rh = (x2 - x1), (y2 - y1)\n",
    "    dx, dy = abs(cx - rx)/(rw/2 + 1e-6), abs(cy - ry)/(rh/2 + 1e-6)\n",
    "    d = np.sqrt(dx*dx + dy*dy)\n",
    "    return max(0.0, 1.0 - min(1.0, d))\n",
    "\n",
    "############################################\n",
    "# 4) TTS + RATE-LIMITING\n",
    "############################################\n",
    "\n",
    "def _init_tts_engine():\n",
    "    eng = pyttsx3.init()\n",
    "    try:\n",
    "        for v in eng.getProperty('voices'):\n",
    "            name = (v.name or '').lower()\n",
    "            lang = ''.join(v.languages).lower() if hasattr(v, 'languages') else ''\n",
    "            if 'pt' in lang or 'portugu' in name:\n",
    "                eng.setProperty('voice', v.id)\n",
    "                if 'br' in lang or 'braz' in name:\n",
    "                    break\n",
    "    except: pass\n",
    "    eng.setProperty('rate', 250)\n",
    "    eng.setProperty('volume', 1.0)\n",
    "    return eng\n",
    "\n",
    "_tts_engine = _init_tts_engine()\n",
    "_tts_queue = Queue(maxsize=6)\n",
    "_tts_lock = threading.Lock()\n",
    "\n",
    "def _tts_worker():\n",
    "    while True:\n",
    "        t = _tts_queue.get()\n",
    "        try:\n",
    "            start_time = time.time()  # marca início\n",
    "            print(f\"[TTS] Falando: {t}\")\n",
    "            _tts_engine.say(t)\n",
    "            _tts_engine.say(\".\")\n",
    "            _tts_engine.runAndWait()\n",
    "            end_time = time.time()  # marca fim\n",
    "            elapsed = end_time - start_time\n",
    "            print(f\"[TTS] Tempo usado: {elapsed:.2f} segundos\")\n",
    "        except: pass\n",
    "        _tts_queue.task_done()\n",
    "\n",
    "threading.Thread(target=_tts_worker, daemon=True).start()\n",
    "\n",
    "_last_speak_ts = 0.0\n",
    "_last_alert_ts = 0.0\n",
    "MIN_SPEAK_GAP_S = 0.1\n",
    "MIN_ALERT_GAP_S = 0.1\n",
    "per_target_cooldown = {}\n",
    "TARGET_COOLDOWN_S = 8\n",
    "\n",
    "NOMES_PT = {\n",
    "    'person': 'pessoa',\n",
    "    'bicycle': 'bicicleta',\n",
    "    'car': 'carro',\n",
    "    'bench': 'banco',\n",
    "    'chair': 'cadeira',\n",
    "    'stop sign': 'placa de pare',\n",
    "    'potted plant': 'planta'\n",
    "}\n",
    "\n",
    "def _fmt_metros(x): return f\"{x:.1f}\".replace('.', ',')\n",
    "def _dir_from_bbox(center, roi):\n",
    "    cx, cy = center; x1, y1, x2, y2 = roi\n",
    "    t = (x1 + (x2 - x1)/3, x1 + 2*(x2 - x1)/3)\n",
    "    return \"à esquerda\" if cx < t[0] else \"à direita\" if cx > t[1] else \"à frente\"\n",
    "\n",
    "def speak(txt, priority=False):\n",
    "    global _last_speak_ts, _last_alert_ts\n",
    "    now = time.time()\n",
    "    if priority:\n",
    "        if now - _last_alert_ts < MIN_ALERT_GAP_S: return\n",
    "        with _tts_lock:\n",
    "            try:\n",
    "                while not _tts_queue.empty():\n",
    "                    _tts_queue.get_nowait()\n",
    "                    _tts_queue.task_done()\n",
    "                _tts_engine.stop()\n",
    "            except: pass\n",
    "        _last_alert_ts = now\n",
    "    else:\n",
    "        if now - _last_speak_ts < MIN_SPEAK_GAP_S: return\n",
    "        _last_speak_ts = now\n",
    "    try:\n",
    "        _tts_queue.put_nowait(txt)\n",
    "    except: pass\n",
    "\n",
    "############################################\n",
    "# 5) LOOP PRINCIPAL\n",
    "############################################\n",
    "\n",
    "video_path = 'C:/codes/unicamp/MC949/T3/videos/VID_20251014_120019333.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "prev_time = time.time()\n",
    "prev_gray = None\n",
    "frame_idx = 0\n",
    "\n",
    "while True:\n",
    "    ok, frame = cap.read()\n",
    "    if not ok: break\n",
    "    frame_idx += 1\n",
    "    if FAST_MODE and frame_idx % (FRAME_SKIP+1) != 0:\n",
    "        continue\n",
    "\n",
    "    h, w = frame.shape[:2]\n",
    "    roi = get_roi(frame)\n",
    "    cv2.rectangle(frame, (roi[0], roi[1]), (roi[2], roi[3]), (255, 255, 0), 2)\n",
    "\n",
    "    invdepth = predict_depth(frame)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    flow = None\n",
    "    if USE_FLOW:\n",
    "        if prev_gray is not None:\n",
    "            flow = cv2.calcOpticalFlowFarneback(prev_gray, gray, None, 0.5, 3, 21, 3, 5, 1.2, 0)\n",
    "        prev_gray = gray.copy()\n",
    "\n",
    "    results = yolo(frame, verbose=False)\n",
    "    _auto_calibrate_scale(results, invdepth, frame.shape)\n",
    "\n",
    "    candidates = []\n",
    "    for r in results:\n",
    "        for b in r.boxes:\n",
    "            cls = yolo.names[int(b.cls)]; conf = float(b.conf)\n",
    "            if conf < 0.45 or cls not in CLASSES_UTEIS: continue\n",
    "            x1, y1, x2, y2 = map(int, b.xyxy[0])\n",
    "            cx, cy = bbox_center((x1, y1, x2, y2))\n",
    "            if not (roi[0] < cx < roi[2] and roi[1] < cy < roi[3]): continue\n",
    "\n",
    "            x1c, y1c = max(0, x1), max(0, y1)\n",
    "            x2c, y2c = min(w, x2), min(h, y2)\n",
    "            box_depth = invdepth[y1c:y2c, x1c:x2c]\n",
    "            if box_depth.size == 0: continue\n",
    "            inv_med = float(np.median(box_depth))\n",
    "            dist_m = invdepth_to_meters(inv_med)\n",
    "            mx, my, mmag = mean_flow_in_bbox(flow, (x1c, y1c, x2c, y2c))\n",
    "            approach = mmag + max(0.0, -my)\n",
    "            cweight = center_weight_in_roi(cx, cy, roi)\n",
    "            candidates.append({\n",
    "                'bbox': (x1, y1, x2, y2),\n",
    "                'cls': cls,\n",
    "                'conf': conf,\n",
    "                'dist_m': dist_m,\n",
    "                'flow_mag': mmag,\n",
    "                'approach': approach,\n",
    "                'center_w': cweight,\n",
    "                'center': (cx, cy)\n",
    "            })\n",
    "\n",
    "    target = None\n",
    "    if candidates:\n",
    "        for c in candidates:\n",
    "            inv_d = 1.0 / (c['dist_m'] + 1e-6)\n",
    "            c['score'] = 1.5*inv_d + 1.0*c['center_w'] + 0.8*c['approach']\n",
    "        target = max(candidates, key=lambda x: x['score'])\n",
    "\n",
    "    for c in candidates:\n",
    "        x1, y1, x2, y2 = c['bbox']\n",
    "        color = (0, 0, 255) if target and c is target else (0, 255, 0)\n",
    "        txt = f\"{c['cls']} {c['dist_m']:.1f}m\"\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "        cv2.putText(frame, txt, (x1, max(20, y1-8)), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "\n",
    "    # --- DEBUG VISUAL ---\n",
    "    status = \"CALIBRANDO...\" if _calibrating_frames < 15 else \"OK\"\n",
    "    scale_txt = f\"Escala: {_dynamic_scale:.2f} | {status}\"\n",
    "    cv2.putText(frame, scale_txt, (15, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (50, 255, 50), 2)\n",
    "    if _last_debug_dist:\n",
    "        cv2.putText(frame, f\"Ref pessoa: {_last_debug_dist:.1f}m\", (15, 50),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)\n",
    "        \n",
    "    curr_time = time.time()\n",
    "    fps_display = 1.0 / (curr_time - prev_time)\n",
    "    prev_time = curr_time\n",
    "    cv2.putText(frame, f\"FPS: {fps_display:.1f}\", (15, 75),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)\n",
    "    # --------------------\n",
    "    \n",
    "\n",
    "    alert_text = \"\"\n",
    "    if target:\n",
    "        near = target['dist_m'] <= DIST_DANGER_M\n",
    "        fast = target['approach'] >= FLOW_APPROACH_MIN\n",
    "        centered = target['center_w'] >= (1.0 - CENTER_BONUS)\n",
    "        if (near and fast) or (near and centered):\n",
    "            alert_text = f\"ALERTA: {target['cls']} a {target['dist_m']:.1f} m\"\n",
    "            cv2.putText(frame, alert_text, (20, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 3)\n",
    "\n",
    "    if target:\n",
    "        direction = _dir_from_bbox(target['center'], roi)\n",
    "        # alvo_key = (target['cls'], direction)\n",
    "        alvo_key = (target['cls'])\n",
    "        if alert_text:\n",
    "            cls_pt = NOMES_PT.get(target['cls'], target['cls'])\n",
    "            dist_txt = _fmt_metros(target['dist_m'])\n",
    "            acao = \"Pare.\" if direction == \"à frente\" else \\\n",
    "                   \"Desvie à esquerda.\" if direction == \"à direita\" else \"Desvie à direita.\"\n",
    "            fala = f\"Alerta! {cls_pt} a {dist_txt} metros {direction}. {acao}\"\n",
    "            speak(fala, priority=True)\n",
    "        else:\n",
    "            now = time.time()\n",
    "            if now - per_target_cooldown.get(alvo_key, 0.0) >= TARGET_COOLDOWN_S:\n",
    "                cls_pt = NOMES_PT.get(target['cls'], target['cls'])\n",
    "                dist_txt = _fmt_metros(target['dist_m'])\n",
    "                speak(f\"{cls_pt} a {dist_txt} metros {direction}.\", priority=False)\n",
    "                per_target_cooldown[alvo_key] = now\n",
    "\n",
    "    cv2.imshow(\"Etapa 4 - Modo Rápido CPU (AutoCalib + Debug)\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
